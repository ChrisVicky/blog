{"posts":[{"title":"About Me","text":"Hello, and welcome to my blog. My Arch Linux & Dwm","link":"/2022/11/12/2022-11-13-aboutme/"},{"title":"Deploy Hadoop with VirtualBox","text":"This post is a reminder of hadoop deployment on Arch Linux and virtualbox (with vagrant) Related Github Repo contains resource: system information Pre-Requirement VirtualBox vagrant virtualbox and vagrant Access to Internet The base OS we choose to deploy Hadoop Cluster is Ubuntu 16, thus we should be able to fetch “ubuntu/xenial64” from vagrant cloud. Also, the first step in your vm is to update and install necessary applications such as ssh, rsync and vim. Installation1. Ingredients checkup Make sure the Directory has the following structure 123456789101112131415161718192021.├── cache -- Files to replace in VM│ ├── core-site.xml -- replace /usr/local/hadoop/etc/hadoop/core-site.xml in VM│ ├── hadoop-2.9.0.tar.gz -- hadoop │ ├── hdfs-site.xml -- replace /usr/local/hadoop/etc/hadoop/hdfs-site.xml in VM │ ├── hosts -- replace /usr/hosts in VM│ ├── jdk-8u161-linux-x64.tar.gz -- jdk package│ ├── mapred-site.xml -- replace /usr/local/hadoop/etc/hadoop/mapred-site.xml│ ├── scala-2.11.8.tgz -- scala package│ ├── sources.list -- replace /etc/apt/sources.list -&gt; from https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu/│ ├── spark-2.3.0-bin-hadoop2.7.tgz -- spark package│ └── yarn-site.xml -- replace /usr/local/hadoop/etc/hadoop/yarn-site.xml├── hadoop+spark集群平台搭建.pptx -- ppt instruction for Hadoop + spark on VMware├── Hadoop集群安装手册.pdf -- PDF instruction for Hadoop on VMware based on CentOS├── hadoop集群搭建.pptx -- ppt instruction for Hadoop on VMware based on Ubuntu -- Instruction for this Virtualbox Version├── img -- IMGs in this readme file├── init.sh -- Scripts to execute when VM first starts├── README.md -- This file└── Vagrantfile -- VM Configurations2 directories, 26 files 2. Check init.sh and Vagrantfile for certain configurations The default configuration for Virtual Machines is written in Vagrantfile. Modifications can be made by changing the code directly. Check up init.sh for more setups. 3. Execute Vagrant Up In the directory shown above, execute vagrant up to setup and boot your vm. 1vagrant up Commands to Execute It should take a while. So have a cup of tea and when everything is settled, check your virutal machine with either vagrant status or virtualbox user interface 1vagrant status vagrant status virtualbox user interface 4. ssh configurations use vagrant ssh master to enter master virtual machine. 1vagrant ssh master vagrant ssh master Append public keys to authorized_keys by cat /vagrant/cache/authorized_keys &gt;&gt; ~/.ssh/authorized_keys 1cat /vagrant/cache/authorized_keys &gt;&gt; ~/.ssh/authorized_keys Note that all three public keys have been generated and pasted in /vagrant/cache/authorized_keys by commands in init.sh and Vagrantfile. Ssh configuration should be done in both slaves as well. Varify ssh configuration by executing ssh slave1 in master virtual machine. You sohuld log into slave1 without entering password. log into slave1 without password after ssh configuration Deploy and Varify Hadoop1. Deploy Hadoop run hadoop namenode -format in master virtual machine to configure node information. 1hadoop namenode -format run start-all.sh to start deployment. Always remember to run stop-all.sh before virtual machine shutdown. 2. Varification run hadoop jar hadoop-mapreduce-examples-2.9.0.jar pi 5 5 in directory /usr/local/hadoop/share/hadoop/mapreduce to varify.12cd /usr/local/hadoop/share/hadoop/mapreducehadoop jar hadoop-mapreduce-examples-2.9.0.jar pi 5 5 A number relatively close to pi is then presented. To be more accurate on the result, try running pi 10 10000 which takes a longer period. 3. User Interface Hadoop Environment Configuration on IP:50070 where IP is the static IP for Master. And on IP:8088 where IP is the static IP of Master and 8088 can be configured in those .xml files. UI","link":"/2024/10/15/2022-11-15-deploy-hadoop/"},{"title":"Add Extra Memory to Thinkpad T14","text":"Working on hard projects with Hadoop cluster really runs out the limit of my poorly configured laptop. Therefore, I decide to add an extra memory card to it to boost the performance. 1. Check the hardware information Before cracking down the shell, we should figure out whether my laptop has a spare set for the extra memory and what kinds of memory card should I buy. To do that, we perform the following command to monitor the hardware status1sudo dmidecode memory &gt; memory.log command output Note: I’ve accidentally removed memory.log which generated before adding the extra memory, and this screenshot is taken after the card is inserted. According to the output, the maximum Capacity of Memory of my laptop is 32 GB, meaning that it is capable of accepting an extra memory of 16 GB. Another important information here is the speed. Because both memory cards will be accessed with the same bus, the slower speed could be a bottle net. I bought a memory card from Samsung with the same speed and data width for 300 RMB on Taobao. 2. Opening the Laptop Using tools from the shop, the laptop is rather easy to tear. The only thing to mention here is that, be gentle not to break the machine down and after insertion, do not fix the screw before the evaluation process succeeds. In fact, the work can be down with a screwdriver, and a student ID card. 3. Evaluation After insertion, boot the machine and enter the Operating System to check whether the extra Memory works well. Successfully Boot up Heavy Virtual Machines after Installation of the Additional 16GB Memory Card","link":"/2024/10/15/2022-11-18-Add-Extra-Memory-to-Thinkpad-T14/"},{"title":"Setup Systemd for clash Proxy","text":"Since I live in China mainland, some specific websites can’t get accessed without a Vpn service running on the laptop. I managed to get one using clash and configuration. However, I have to run ./clash -d . manually every-time I need access, which is inconvenient. Since I’ve been using Linux, I did some search and managed to set up a system task that runs automatically after booting. Here is the Memo Add clash@.service in /usr/lib/systemd/system/ or in /etc/systemd/system/ Example 123456789101112[Unit]Description=A rule based proxy in Go for %i.After=network.target[Service]Type=simpleUser=%iRestart=on-abortExecStart=/home/christopher/.config/clash/clash[Install]WantedBy=multi-user.target Use systemctl to enable and start mission. Systemd Management","link":"/2022/12/09/2022-12-09-Setup-Systemd-for-clash-Proxy/"},{"title":"SSH Penetration Setup Memo","text":"Background We have deployed a web application demo on a computer whose network access is limited within school and cannot be accessed from devices outside. Plus that we know from the man page of ssh that ssh -R could perform a proxy that transfers data stream from one port to another, thus, we decide to make use of a server bought from Aliyun as a repeater, or bridge, that connects our clients to the application. How to do it For specification, we call the computer with the deployment of our web application as A and its port as AP while the server is called B, BP1, BP2. First on computer A 1ssh -fCNR `BP1`:localhost:`AP` -o ServerAliveInterval=60 serverName@serverIP On Server 1ssh -fCNL 0.0.0.0:`BP2`:localhost:`BP1` localhost It works like this Graph Access through internet Access","link":"/2022/12/01/2022-12-01-ssh/"},{"title":"Source Backup for Disk Update","text":"Background 作为大学生，只有一台 Thinkpad T14 Gen 1 的笔记本却安装了 Arch Linux，而由于课程需要仍保留了大部分 Windows 11 的系统，长期以来的使用，让 512 GB 的存储空间告急，于是打算更换一块 1T 的固态硬盘。在此对磁盘更换做一个记录。 准备文件分类 第一大类：系统文件， 如 Windows 等 Operating Systems 的文件 不考虑保存，但需要先查清除如何对 Windows 11 下的 Office 全家桶进行恢复。 第二大类：工程文件； 2-1. 项目、代码等 存入 github 代码库，将不必要保存的 tmp 文件删除 写好 README 文档 2-2. 安装包、dependency 丢弃，实际使用时再安装 第三大类：资源文件： 3-1. 课程文件等 打包按时间排序 项目类文件保存两份 3-2. 配置文件 重要配置打包或上传 github 3-3. 字体 不能打包，但需要确定安装和配置方案 3-3. 其他资源 写个 README 计划 文件备份 根据上述分类进行备份 2022-12-12 23:38 DONE 确定安装和磁盘分区 安装 512 GB 的 Windows 11 系统 和 512 GB 的 Linux 系统 Linux 安装 DWM + Xorg （需要先写好安装文档以便查看） 购置固态硬盘 选取三星 “980 Pro PCIe 4.0 NVMe M.2” 2022-12-12 23:38 次日到貨 对需要安装的系统和软件、配置写教程 待安装（配置）的内容 教程 备注 Arch Linux viseator的博客 dwm 拷贝文件即可, 应当包括 autostart dmenu 同上 vim / nvim 同上 中文输入法 中文輸入法等安裝 yay yay git repo clash 我的博客 navicat 已經完成拷貝 apifox vivado Vivado HLx 2019.2: All OS installer Single-File Download (TAR/GZIP - 26.55 GB) libfreenect2 libfreenect2 Github!! 十分重要 opencv yay 将就用一下先 virtualbox 我的博客","link":"/2024/10/15/2022-12-12-Source-Backup-for-Disk-Update/"},{"title":"KinectV2 Camera Calibration and &#96;Yolov5&#96; Recognition","text":"Project Repo: KinectV2 Camera Calibration and Yolov5 Recognition 2022-12-30 19:11 This is a subproject from camera-position-solution. BackgroundWe are assigned the mission to combine KinectV2 Camera and a Robot car to construct a system that automatically calculate the camera’s position and can tell where some objects are only according to camera’s perspective (Of course here we use Yolov5 to recognize objects); KinectV2 In this part, we use the chess board instead of the robot car to accomplish the calibration part and then calculate a perspective transformation matrix that maps points in the image (aka pixel coordinates) to the desk (or bed) coordinates. Project Structure123456789101112131415161718192021222324252627.├── build -- build Dir├── CMakeLists.txt -- Top Cmake Configuration├── data │ └── output.mp4 -- Output Data -&gt; stacks of imshown frames├── default.xml -- Default Configuration File (example)├── include │ ├── calibration.hpp -- Calibration -&gt; Future change: With Robot│ ├── define.hpp -- Define COLORS etc│ ├── dnn.hpp -- Use OpenCV DNN APIs│ ├── main.hpp -- Main Program│ └── settings.hpp -- Read Settings├── logsrc -- Log Helper by loguru│ ├── CMakeLists.txt│ ├── loguru.cpp│ └── loguru.hpp├── models -- Trained Yolov5 Modules│ ├── yolov5n.onnx│ ├── yolov5s.onnx│ ├── yolov5.xml│ └── yuki-bubu-2022-12-23.onnx ├── README.md └── src ├── calibration.cpp ├── dnn.cpp └── main.cpp21 directories, 87 files Dependency We use two libraries: Libfreenect2 and OpenCV. Note that: You should set freenect2_DIR and include freenect2_INCLUDE directions if you install libfreenect2 in custom directories. 12345# Set up libfreenect2# Set include dir and DIR for libfreenect2 if it is not installed globally# SET(freenect2_DIR /home/christopher/Coding/libfreenect2/freenect2/lib/cmake/freenect2)# include_directories(/home/christopher/Coding/libfreenect2/freenect2/include/)find_package(freenect2 REQUIRED) Program Usage Install Dependencies shown above Run the following commands to build the project 123mkdir -p build &amp;&amp; cd buildcmake ..cmake --build . Plug in KinectV2 via USB (you might need a hub) run ./calibration to start program Developer Diary To meet the need, we have to conquer four difficulties. KinectV2 Connection OpenCV Calibration Object Detection Planes Transformation 1. KinectV2 ConnectionSince we develop the program on multiple Operating Systems (OS), we decide to take advantage of Libfreenect2 which is open-sourced and supports Linux, Windows and Mac-OS. To install Libfreenect2, we simply go through the steps described on the README page of the project. Note that I’m running the Arch Linux with 6.0.12 Linux Kernel at the time of this post, and the lib works fine. To use KinectV2, we need the following steps: 1.1. Define Basic Variables, either globally or locally.12345libfreenect2::Freenect2 freenect2; // libfreenect2 entitylibfreenect2::PacketPipeline *pipeline; // libfreenect2 pipelinelibfreenect2::Freenect2Device *device; // devicelibfreenect2::SyncMultiFrameListener listener(libfreenect2::Frame::Color);libfreenect2::FrameMap frames; 1.2. Initialize the device via certain APIs12345678910111213141516171819202122/* -------------------- START Kinectv2 Initialization -------------------- */if(freenect2.enumerateDevices() == 0){ LOG_F(ERROR, &quot;no device connected!&quot;); return -1;} else { LOG_F(INFO, &quot;device connected&quot;);}string serial = freenect2.getDefaultDeviceSerialNumber();LOG_F(INFO, &quot;SEARIAL Number: %s&quot;,serial.c_str());pipeline = new libfreenect2::CpuPacketPipeline();device = freenect2.openDevice(serial, pipeline); if(device == 0){ LOG_F(ERROR, &quot;failed to open device: %s&quot;, serial.c_str()); return -1;} else { LOG_F(INFO, &quot;device opened&quot;);}kinect_shutdown = false;device-&gt;setColorFrameListener(&amp;listener);device-&gt;start();LOG_F(INFO, &quot;device serial: %s&quot; ,device-&gt;getSerialNumber().c_str());LOG_F(INFO, &quot;device firmware: %s&quot; ,device-&gt;getFirmwareVersion().c_str());/* -------------------- END Kinectv2 Initialization -------------------- */ 1.3. We shall start a Loop to receive frames from the Device12345678while(!kinect_shutdown){ if(!listener.waitForNewFrame(frames, timeout)) LOG_F(WARNING, &quot;Frame Received Failed after timeout: %d&quot;, timeout); libfreenect2::Frame *rgb = frames[libfreenect2::Frame::Color]; /* -------------------- START Frame Processing -------------------- */ /* -------------------- END Frame Processing -------------------- */ listener.release(frames);} 1.4. Before Exit, we need to manually stop and close the device12device-&gt;stop();device-&gt;close(); We must define a sigint_handler to handle crash-down exit, or the device just go on pushing frames to stack via USB and never stops until the computer shutdown. 1234567void sigint_handler(int s){ device-&gt;stop(); device-&gt;close(); exit(s);}// Usage signal(SIGINT, sigint_handler); // Savely Close the Device before sudden exit 1.5. To take advantage of OpenCV APIs, we convert libfreenect2::Frame to cv::Mat right at the beginning of Frame Processing.1234cv::Mat(rgb-&gt;height, rgb-&gt;width, CV_8UC4, rgb-&gt;data).copyTo(kinect_mat);cv::flip(kinect_mat, kinect_mat, 1);rgb_mat = cv::Mat::zeros(kinect_mat.size(),CV_8UC3);mixChannels(kinect_mat, rgb_mat, {0,0,1,1,2,2}); Note that: libfreenect2::Frame contains 4 channels while our yolov5 model takes only 3-channel inputs, so we perform a mixChannels() here to reduce the last one. 2. OpenCV CalibrationTo be more specified, in our original plan, the robot car, armed with SLAM, would provide information in 3D-world-coordinate-system while the KinectV2 camera shall recognize the car via some sort of object-recognition technic (e.g. YoloV5) and provides its position in 2D-pixel-coordinate-system. Timestamp enables us to match them up, forming a set of 2D-3D points pair. Therefore, the problem turns into a Perspective-n-Point(aka PnP) problem, and it has been solved long ago. OpenCV provides multiple APIs that implement nearly every solution posted literally. However, because of the COVID-19 lockdown, I was separated from my teammates and I only have the KinetV2 camera by hand. Thus, I use built-in calibration functionality with chessboard to obtain the set of 2D-3D points pair to accomplish the task. We perform 4 steps to meet the need. 2.1. Collect multiple frames where the camera and chessboard are relatively still.12if(STATE == STATE_START_CALIBRATION) cali_frames.push_back(rgb_mat); Note that: We use STATE to control the program. In fact, the whole program is designed on a Finite-State Machine(FSM). 2.2. Run findPattern to obtain feature points’ position in 2D-pixel-coordinate-system.123vector&lt;Point2f&gt; point_buff;int board_flag = CALIB_CB_ADAPTIVE_THRESH | CALIB_CB_NORMALIZE_IMAGE | CALIB_CB_FAST_CHECK;int found = findChessboardCorners(rgb_mat, boardSize, point_buff, board_flag); Note that: We use PThread to accelerate the process, finding patterns in all collected frames at once. 2.3. Collect all 2D information and calculate 3D-world-coordinate-system information.12345678910111213int found=0;for(int i=0;i&lt;size;++i){ void * ret; pthread_join(thread_ids[i], &amp;ret); runCalibrationRet retVal = *(runCalibrationRet*) ret; if(retVal.found){ if(!found) d2s = retVal.d2; else for(int j=0;j&lt;d2s.size();j++) d2s[j] += retVal.d2[j]; found ++; }} 123for(int i=0;i&lt;boardSize.height; ++i) for(int j=0;j&lt;boardSize.width; ++j) d3s.push_back(Point3f(j*squareSize, i*squareSize, 0)); Note that: 3D-world-coordinate-system information is defined manually. The chessboard is the perfect coordinate system. 2.4. Wrap them up and perform solvePnP to get rvec and tvec1solvePnP(d3s, d2s, camera_matrix, dist_coeffs, rvec, tvec); Note that:camera_matrix and dist_coeffs are both ‘known’ parameters. They can be obtained either through manufacturer or calibrated by programs. OpenCV provides one API and with a little patch shall we be able to calibrate it. 2.5. To obtain camera position, we still need another step that takes both rvec and tvec as input and camera_position would be obtained.123456789int type_tv = tv.type();Mat rvf(3,3,type_tv);// Convert from vector rv(3x1) to matrix rotation(3x3)Rodrigues(rv, rvf);// The Inversed MatrixMat rvf_1(3,3,type_tv);invert(rvf, rvf_1, DECOMP_SVD);Mat Position = rvf_1 * (-tv);Point3f p(Position); Note that: In Computer Vision, there are four basic coordinate systems and here we use the ‘extrinsic’ matrix, which converts between 3D-world-coordinate-system and 3D-camera-coordinate-system, to calculate camera position. For detail: OpenCV Pnp reference. Also note that: Rodrigues is essential, the output, rvec is (3x1), reference: Rodrigues 3. Object DetectionAccording to our original plan, the KinectV2 Camera should recognize the Robot car in order to obtain its position in 2D-pixel-coordinate-system. So I perform a test with the famous YoloV5 Project. The hardest part here is not the training part, YoloV5 provides a rather simple API to format data and train it on pre-trained models (reference: Train on Custom Data). The hardest part is to mix the model in C++ program. After some research, I find that OpenCV provides APIs cv::dnn that load .onnx models and can run forward actions, or deduction. In this part, I use my two cats as dataset. In the following steps, I would demonstrate the way to set up datasets, train model and use the model via OpenCV APIs. 3.1. Dataset CreationSimply follow steps described on this page. The output should be similar as below: 12345678.├── data.yaml├── README.dataset.txt├── README.roboflow.txt├── test├── train└── valid9 directories, 382 files 3.2 Train modelSimply put datasets in yolov5 directory and perform the following command and sit back to wait for the results 1python train.py --img 640 --batch 16 --epochs 3 --data data.yaml --weights yolov5s.pt Note that: You should clone yolov5 repo before training and of course set up python environment. 3.3 Convert model to .onnxYoloV5 takes PyTorch as backend, thus, the models are saved as .pt format. However, cv::dnn prefers .onnx format. Thus, a conversion shall be performed. At this point (2022-12-30), the transformation based on the default dependency of YoloV5 is not compatible with the latest version of OpenCV dnn module. I have posted an Issue on this to YoloV5 and get the information that it is the OpenCV that can not decode the model. Somehow, I manage to conquer the issue by downgrading some essential packages. My anaconda environment configuration is uploaded within the project. After the correction of Dependency, we perform the following command to export .onnx from .pt. 1python export.py --weights yolov5s.pt --include onnx 3.4 Load .onnx with OpenCV123cv::dnn::Net net = cv::dnn::readNetFromONNX(model_path);net.setPreferableBackend(cv::dnn::DNN_BACKEND_OPENCV);net.setPreferableTarget(cv::dnn::DNN_TARGET_CPU); 3.5 Format Input Data1234567cv::Mat blob;int col = frame.cols;int row = frame.rows;int _max = max(col, row);input_img = cv::Mat::zeros(_max, _max, CV_8UC3);frame.copyTo(input_img(cv::Rect(0, 0, col, row)));cv::dnn::blobFromImage(input_img, blob, 1./255., cv::Size(INPUT_WIDTH, INPUT_HEIGHT), cv::Scalar(), true, false); 3.6 Forward Network123net.setInput(input);std::vector&lt;cv::Mat&gt; outputs;net.forward(outputs, net.getUnconnectedOutLayersNames()); 3.7 Format the outputThe output of the model, as the result of network-forwarding, is defined as follows: 1234567 structure of `output.data`┌─┬─┬─┬─┬─┬────────┬─────────────────────►│0│1│2│3│4│5 ......│dimensions├─┼─┼─┼─┼─┼────────┼─┬─┬─┬─┬─┬────────┬──►│x│y│w│h│c│[scores]│x│y│w│h│c│[scores]│..└─┴─┴─┴─┴─┴────────┴─┴─┴─┴─┴─┴────────┴──► c: confidence Basically, it is an array that can be accessed via its address. The code is too large to be shown here. 3.8 Transfer Output to DetectionFor easy access, we transfer the output to the following data format. 12345struct Detection{ int class_id; // Result's class id float confidence; // Probability cv::Rect box; // Where it is}; 3.9 Draw Boxes around Targets12345678910int detection_size = output.size();for(int i=0;i&lt;detection_size;++i){ auto detection = output[i]; auto box = detection.box; auto class_id = detection.class_id; const auto color = color_list[class_id%color_list.size()]; cv::rectangle(frame, box, color, 2); cv::rectangle(frame, cv::Point(box.x, box.y - 20), cv::Point(box.x + box.width, box.y), color, cv::FILLED); cv::putText(frame, cv::format(&quot;%s: %.3f&quot;,s.classifications[class_id].c_str(),detection.confidence), cv::Point(box.x, box.y - 5), cv::FONT_HERSHEY_COMPLEX, 0.6, BLACK);} 4. Plane TransformationFinally, we convert any points on the 2D-pixel-coordinate-system to its position in the 3D-world-coordinate-system. However, according some hard math, it is not possible to convert 2D to 3D without a given plane. Shown below, here is a model of Computer Vision (Reference: ResearchGate) Take the example of the transformation of Point $^1p_1$. The 3D position of it can be anywhere on the line of $O\\ ^1p_1$, not necessary be at Point $^wp_1$ unless we require the 3D position lies on a particular plane. Thus, in our case, we explicitly define that the Z axis of the object must be 0, meaning that we only provide the position of it on the ground $XOY$ axis and not provide the height. Then, the problem is simplified to calculate a transformation between two planes. Here we take advantage of another API by OpenCV: getPerspectiveTransformation. According to the definition below, the input src and dst must be vertices of a quadrangle. And the return value shall be the transformation matrix. 4.1 Calculate Transformation MatrixIn our project, we take 4 vertices of the chessboard to be the input. 123456789101112131415161718vector&lt;Point2f&gt; desk;for(auto d3:d3s) desk.push_back(Point2f(d3.x,d3.y));Point2f in[4];Point2f out[4];#define helper(_in, in_) \\_in[0] = in_[i0]; \\_in[1] = in_[i1]; \\_in[2] = in_[i2]; \\_in[3] = in_[i3]int i0 = 0, i1 = boardSize.width-1;int i2 = boardSize.width * (boardSize.height-1);int i3 = boardSize.width * boardSize.height - 1;helper(in, d2s);helper(out, desk);#undef helper// NOTE: According to reference (Opencv), // getPerspectiveTransform takes quadrangle vertices in the source imagepix23D = getPerspectiveTransform(in, out); 4.2 Calculate Corresponding 3D PositionperspectiveTransformation have already done for us. 1234vector&lt;Point2f&gt; out;vector&lt;Point2f&gt; in; in.push_back(p2);cv::perspectiveTransform(in, out, pix23D);Point3f ret = Point3f(out[0].x,out[0].y,0); SummaryTill now, the Project is half-way finished and seems pretty simple, only taking advantage of existing Methods, APIs and Models. In the next semester, we would combine the robot car to accomplish the original plan. The next aim of our project would be human-skeleton detection and action deduction with it. And finally, adding some WiFi-Sensor Information would enable us to build a more robust and more complete in-home monitor system.","link":"/2024/10/15/2022-12-30-KinectV2-Camera-Calibration-and-YoloV5-Recognition/"},{"title":"Paper Review: An Image is Worth 16x16 Words","text":"Title Cite: Dosovitskiy, Alexey, et al. “An image is worth 16x16 words: Transformers for image recognition at scale.” arXiv preprint arXiv:2010.11929 (2020). Available online: https://arxiv.org/pdf/2010.11929.pdf Date: 2023-01-15 22:07 Brief summary What is the problem the paper is trying to solve? How can we reduce CNNs in transformer models in image classification tasks? How to treat an Image as a sequence of data? What are the key ideas of the paper? Key insights? A new way to treat an image sequentially. An image is divided into 16x16 2D patches and are transferred sequentially into an out-of-box self-attention transformer encoder, followed by MLP Heads which result in classification predictions. What is the key contribution to the literature at the time it was written? First to reduce entirely the CNNs in usage of transformer in image classification tasks and propose a pure transformer model called Vision Transformer (ViT). Maybe the first to propose a sequential treatment on an image. What are the most important things you take out from it? A possible way to treat an image as a sequence of data while preserving some relative information. Designing easy-to-use models that utilize out-of-box interfaces could be a good way of conducting creative methods that solve difficult problems. Strengths (Most Important Ones) Does the paper solve the problem well? First, it is true that the solution, or more precisely, the new model proposed can be a possible solution that treat an image sequentially. Second, the computational latency can be low in this case since the division is as small as 16x16, and therefore the computational complexity can be relatively at a low level. Weaknesses (Most Important Ones) Room for improvement. The way to treat the image as a sequence of data is too straight-forward. The information on the boarders between patches can be lost. The patches are produced with a fixed number of sequences, making the model difficult to perform on images with height resolution, and since nowadays, people have a preference of taking high resolution pictures, the methods proposed may not be practical in real-life without further improvements. Also, the model requires a large quantity of data for training, significantly improving the training costs. How can we do better? Your ideas and thoughts. To include more relative information between patches, I guess one way is to introduce an additional division that stands on the boarder of the original one. A possible implementation is shown below. 12345678┌───┬───┬───┐ ┌─┬───────┬─┐ ┌─┬─┬───┬─┬─┐│ │ │ │ ├─┼───────┼─┤ ├─┼─┼───┼─┼─┤├───┼───┼───┤ │ │ │ │ ├─┼─┼───┼─┼─┤│ │ │ │ + │ │ │ │ =&gt; │ │ │ │ │ │├───┼───┼───┤ │ │ │ │ ├─┼─┼───┼─┼─┤│ │ │ │ ├─┼───────┼─┤ ├─┼─┼───┼─┼─┤└───┴───┴───┘ └─┴───────┴─┘ └─┴─┴───┴─┴─┘ A B C Where A is the method in the paper and B is the additional sequence to provide extra information. But again, this additional patch can further worsen the situation of high overall computational costs. The high computational costs in high resolution image processing may be decreased by parallel hardware devices. What have you learnt/enjoyed/disliked in the paper? Why? The most impressive thing I take away from this paper is the methodology that the model is designed to utilize the API of original Transformer model which has been implemented and optimized for efficient performance. This way of design is simple, yet creative and meaningful.","link":"/2023/01/16/2023-01-16-An-Image-is-Worth-16x16-Words/"},{"title":"Paper Review: OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields","text":"Title Cite: Cao Z, Simon T, Wei S E, et al. Realtime multi-person 2d pose estimation using part affinity fields[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 7291-7299. Available Online: https://arxiv.org/pdf/1812.08008.pdf Official Implementation: https://github.com/CMU-Perceptual-Computing-Lab/openpose Demo based on OpenCV Implementation: https://github.com/ChrisVicky/OpenCV-OpenPose-Demo Date: 2023-02-07 Brief summary Main Architecture What is the problem the paper is trying to solve? The Speed-up of Multi-Person Pose Estimation Process, the foundation of many behavior-recognizers. What are the key ideas of the paper? Key insights? Process all people at once. Part Affinity Fields (PAF). PAF Definition What is the key contribution to the literature at the time it was written? The fastest and most accurate model that recognizes pose information is proposed and implemented by the authors. A New Method that utilizing PAF is presented. What are the most important things you take out from it? The idea that using PAF to pair up feature points that belong to one person. The Bottom-Top methodology could reduce redundancy produced by single person recognition in Top-Bottom Methods. Strengths (Most Important Ones) Does the paper solve the problem well? I suppose yes. The paper presents a higher accuracy compared to other models at that time. And According to my own implementation, the paper wins as well. Weaknesses (Most Important Ones) Room for improvement. The pair-up process currently is implemented according to an algorithm after the neural network which, in my opinion, could be merged in the network structure. How can we do better? Your ideas and thoughts. The method relies on a VGG Model that recognizes feature points which can be separated from the main part. Therefore, during video processing where there is a sequence of image data, a pipeline processing structure could be introduced to further improve the efficiency. Also, since VIT, we may replace the Convolutional Neural Network with Transformer. What have you learnt/enjoyed/disliked in the paper? Why? The bottom-up methodology is the most enjoyed idea. However, the feature extractor on the top still presents a Top-Bottom methodology that, in one hand, does reduce the difficulty of development, but on the other hand betrays the Bottom-Top methodology since the model is topped by a feature extractor.","link":"/2023/02/07/2023-02-07-OpenPose-Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/"},{"title":"TJU-快速评教","text":"GitHub Repo 本程序只是为了玩一玩 PlayWright，并不是为了提高评教速度。 使用说明1. 校外使用 连接 TJU 的 VPN 校内登录无需此步骤 打开 easyconnect Arch Linux 用户可以在 aur 上找到。 输入天津大学 VPN 地址 https://vpn.tju.edu.cn并点击按钮。 输入天津大学VPN 输入 VPN 帐号密码。 输入帐号密码 登录完成。 登录完成 2. 安装环境12345conda create -n tjuconda activate tjuconda install pip pip install -r requirement.txtplaywright install chromium 3. 查看并填写配置文件 创建 cfg 文件1cp account.cfg.example account.cfg 修改之12345678910[account]# USERNAME: 学号USERNAME = xxxxxxxx# PASSWORD: 密码PASSWORD = xxxxxxxx# 是否启用 Headless Mode# True: 启用 Headless Mode --&gt; 不显示 UI# False: 不启用 Headless Mode --&gt; 显示 UIHEADLESS = False 4. 运行代码1python main.py 执行效果 关于 playwright PlayWright 有录制功能，能够快速生成脚本，提升开发速度。 1python -m playwright codegen Playwright Codegen","link":"/2023/02/15/2023-02-15-TJU-%E5%BF%AB%E9%80%9F%E8%AF%84%E6%95%99%E8%84%9A%E6%9C%AC/"},{"title":"Git 基本指令记录","text":"Git 基本指令 1. 将远程仓库弄到本地1.0. 将远程仓库克隆到本地 git clone xxx 当本地没有该仓库时 123git clone xxxx# xxxx: 仓库地址（可以是 `https://xxx.git`, 也可以是 ssh 连接 `git@githubxxx`）e.g.: git clone git@github.com:ChrisVicky/TJU-2022-Socket-Computer-Network-Lab.git example 会在本地生成一个目录，包含这个仓库 1.1. 将远程同步到本地仓库 git pull 当本地有该仓库时 每次开始对该仓库内文件修改之前都需要进行 1git pull 2. 做一些修改3. 查看仓库状态 git status12345678910❯ git status On branch main ==&gt; 在主分支（*分支）Your branch is up to date with 'origin/main'. ==&gt; 与远程的 `origin/main` 分支的情况 （*远程分支）Untracked files: ==&gt; 哪些文件没有被 跟踪 （*track） (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) somethingnothing added to commit but untracked files present (use &quot;git add&quot; to track) ==&gt; 总结当前的状况 1234567❯ git statusOn branch mainYour branch is up to date with 'origin/main'.Changes to be committed: ==&gt; 当前有没有被“提交的” 内容 （*commit） (use &quot;git restore --staged &lt;file&gt;...&quot; to unstage) new file: something 如何建立一个“版本”， git 是一个版本控制软件。一个版本就是一个 commit, 一个 commit 中需要 track 多个 changes, 每个 changes 和一个文件绑定 ┌───────────┐ git add ┌────────────┐ git commit ┌───────────┐ │file change│──────────────►│file tracked│───────────────►│file commit│ └───────────┘ └────────────┘ └───────────┘ 新版本诞生 4. 添加到仓库 git add &lt;file&gt;5. 提交到仓库 git commit 需要对提交进行描述 git commit 6. 提交到远程分支 git push","link":"/2023/02/16/2023-02-16-Git-%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B/"},{"title":"数据结构期末复习","text":"MindMap 2023 年复习版 2023-06-16 考试复习版 复习重点绪论 基本概念和术语 时间复杂度计算 线性表 线性表、顺序表、单链表的基本操作和算法 循环链表、双向循环链表操作 栈和队列 栈的定义、特点、基本操作和算法 队列的定义、特点、基本操作和算法 递归 数组和广义表 上三角矩阵、下三角矩阵、稀疏矩阵存储与表示 稀疏存储与表示（矩阵快速转置） 树和二叉树 二叉树定义、性质 二叉树构造 二叉树遍历和算法（递归/非递归） 二叉树应用: 技术 树/森林 和 二叉树转换 哈夫曼树的构建 哈夫曼编码，求加权路径长度 图 图的定义、存储结构 !! 图的遍历（广搜，深搜） Prim 构建最小生成树 拓扑排序实现过程 !! 关键路径实现 !! 给出各事件最早、最晚开始时间，路径上各活动最早、最晚开始时间 最短路径实现过程 查找 顺序表查找、折半查找 二叉排序树查找、插入、删除过程 构造平衡二叉树 B- 树构建、实现 !! 基于哈希函数构建哈希表（散列表） !! 除留余数法解决冲突 线性深测处理 二次深测处理 内排序 直接插入、折半插入、希尔排序 冒泡、快速排序 直接选择、堆排序 归并排序","link":"/2023/06/11/2023-06-11-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/"},{"title":"Github Image Bed","text":"Background It is a catastrophe when trasfering markdown files from one desktop to another without encompassing all the images embeded. Therefore, an image bed is imperative and urgent to be setup. I’ve noticed some solutions on the internet using PicGo. Yet it is not delicate enough since it has to support various platforms. Thus, after discovering, I found Github Api is all you need to full-fill the requirement. Intuitions Image bed does one and the only thing, storing images and being accessed through internet. With Github’s Apis, it is extremely plain to automatically upload images. Github Repo Setup A public-reacheable repo can be easily setup. A Token has be to generated and granted with the following Scopes. The following information must be granted to continue owner: Your Github Name repo: Your Repo Name token: Key to Authorization Program and automation A Program written in Golang is then conducted with Github Api Wrapper, which basically does one thing: Write an image, stored locally, to github and return its url. To embed the Process with my workflow – using vim, I slightly modify the img-paste plugin to use the script. Illustration:","link":"/2023/09/25/2023-09-25-Github-Image-Bed/"},{"title":"School List","text":"Notes Universities in Quebec will not be considered since French plays a vital part in immigration policies of the province. SchoolsUniversity of TorontoRankings #1 (Provincial) #21 (QS) #18 (US News) Location Toronto, Ontari Programs General English Requirement General Regulations: https://sgs.calendar.utoronto.ca/general-regulations NOTE: (2023-09-23) No GRE specifications are found in the Programs of UofT. The word GRE does not even appear in the webpage. MScAC - CS Length: 4 Sessions DDL: Dec/1/2023 General Requirements English TOEFL: 93/120 and 22/30 (W/S) IELTS: 7.0 and 6.5 Three letters of support No Concentration AI Three letters of reference from faculty and/or employers, with preference for at least one such letter from a faculty member in Artificial Intelligence (AI). DS $DS^$* MSc - CS Length: 4 Sessions DDL: Dec/1/2022 2023-09-23: Not yet Opened Three letters of support MASc - ECE Length: 6 Sessions DDL: Jan/4/2024 Master of Applied Science MEng - ECE Length 3 Sessions 6 Sessions (Extened) MSc - Statics Length: 3 Sessions Statistical Theory and Application, Probability DDL: Jan/22/2023 2023-09-23: Not yet Opened University of British ColumbiaRankings #1 (Provincial) #34 (QS) #35 (US) Location Vancouver, British Columbia Programs Overall English Requirements MSc - CS Length: 2Y DDL: Sep/15/2023 to Dec/15/2023 Master of Science in Computer Science English 100/22/21/21/22 - TOEFL/R/W/S/L 7/6.5 - IELTS GRE NOT required Master of Data Sience Length: 10 Months DDL: Nov/3/2023 to Jan/31/2024 Linguistics Vancouver Okanagan NOTE: (2023-09-23) Detailed Requirements are Not Yet Revealed MEng - ECE Length: 12 ~ 16 Months: The MEng program typically takes 12-16 months to complete, but students have up to 5 years to complete the program if they choose. DDL: Oct/15/2023 to Jan/15/2024 Master of Engineering in Electrical and Computer Engineering Official Site: https://ece.ubc.ca/graduate/programs/master-engineering/ The GRE is not required But Welcomed. MASc - ECE Length: 2 Years DDL: Oct/15/2023 to Jan/31/2024 More academic than MEng Official Site: https://ece.ubc.ca/graduate/programs/master-applied-science/ Master of Applied Science in Electrical and Computer Engineering The GRE is not required But Welcomed. MSc - Statistics Length: 1.96 Year: Based on 41 graduations between 2017 - 2020 the minimum time to completion is 1.66 years and the maximum time is 2.99 years with an average of 1.96 years of study. All calculations exclude leave times. DDL: Oct/2/2023 to Jan/7/2024 Master of Science in Statistics The GRE is not required. McGill UniversityRankings #1(Provincial) #30(QS) #54(US) Location Montreal, Quebec Programs Issues with Supervisors are NOT mentioned in program description. English Requirements 86/20 - TOEFL 6.5 for all - IELTS DDL: Sep/15/2023 to Dec/15/2023 M.Sc. - CS | Thesis DDL: Sep/15/2023 to Dec/15/2023 Length: ~2Y The program is designed to take 18-24 months. Students have to register as full-term M.Sc. students (thesis) for three terms (typically in Fall/Winter/Fall) and then often for one additional session (Winter). Official Site: https://www.cs.mcgill.ca/graduate/masters/mscthesis/ M.Sc. - CS | NON-Thesis DDL: Sep/15/2023 to Dec/15/2023 Official Site: https://www.cs.mcgill.ca/graduate/masters/mscnonthesis/ Additional credits can be ful-filled by course-work, internship or research. M.Sc. - ECE | Thesis DDL: Sep/15/2023 to Dec/15/2023 Length: ~2Y Full-time students must complete the degree within three (3) years of initial registration. However, it is possible to complete the program in one and one-half years. software engineering, intelligent systems Official Site: https://www.mcgill.ca/ece/graduate/programinfo/mastereng M.Eng. - ECE | Non-Thesis DDL: Sep/15/2023 to Dec/15/2023 Official Site: https://www.mcgill.ca/ece/graduate/programinfo/master-engineering-non-thesis-project-based-option-retired software engineering, intelligent systems M.A. - Math &amp; Statistics Length: NOT FOUND DDL: Sep/15/2023 to Jan/15/2023 Official Site: https://www.mcgill.ca/mathstat/graduate/prospective-students/admissions Statistics M.M.A. - Analystics Length: 1Y University of AlbertaRankings #1 (Provincial) #111 (QS) #136 (US) Location Edmonton, Alberta Programs If you are applying for a thesis-based program, please note that some programs require you to identify a potential supervisor before applying. ECE DDL: May/1/2024 a Curriculum Vitae Three letters of reference Master of Engineering Length: Typically: one and a half years to two years. Max: six years. course-based Master of Science Length: Typical time of two years is normally required. Max: four years. thesis-based CS DDL: Dec/15/2023 Three letters of reference and a CV. Applicants to a thesis-based MSc are required to select a research area and name up to three professors as potential supervisors. Master of Science Length: 2Y Thesis &amp; Course - Based Versions Master of Science … in Statistical Machine Learning Length: 2Y There is no direct admission to the MSc with a specialization in Statistical Machine Learning. Applicants wishing to pursue this program should apply to the thesis-based MSc; they may apply to transfer to the SML program after one or two terms of study provided a supervisor is found. Math &amp; Statistical Science DDL: NOT FOUND Applicants are encouraged to contact academic staff before applying and identify professors who would be willing to provide supervision. Requirements A Curriculum Vitae A brief (two pages maximum) Personal Statement Three letters of reference Publications (up to a maximum of three) (not required) GRE scores (General and Mathematics) (not required) Master of Science with a specialization in Statistical Machine Learning Length: 2Y Thesis-Based Master of Science with a specialization in Statistics Length: 2Y for Thesis-based | 1Y for Course-based University of WaterlooRankings #2 (Provincial) #112 (QS) #191 (US) Location Waterloo, Ontari ProgramsMMath - CS Length: 2Y DDL: Dec/1/2023 Thesis Supervisors: Finding (Not necessarily required) TOEFL 93 (writing 22, speaking 22), IELTS 6.5 (writing 6.0, speaking 6.5) 3 Reference MASc - ECE Length: 2Y DDL: Feb/1/2024 A supervisor is required to receive an offer of admission Thesis TOEFL 80 (writing 22, speaking 20, reading 20, listening 18), IELTS 6.5 (writing 6.0, speaking 6.0) 2 Reference MEng (Co-op) - ECE Length: 20 Months course-work + co-operative DDL: Feb/1/2024 TOEFL 80 (writing 22, speaking 20, reading 20, listening 18), IELTS 6.5 (writing 6.0, speaking 6.0) MMath - Data Science Thesis-Based DDL: Dec/15/2023 Length: 2Y Supervisors: Finding (Not necessarily required) TOEFL 90 (writing 25, speaking 25), IELTS 7.0 (writing 6.5, speaking 6.5) 3 references MDSAI (Co-op) - DS + AI + Co-op Length: 16 Months Course work ??? TOEFL 100 (writing 26, speaking 26), IELTS 7.5 (writing 7.0, speaking 7.0) MMath - Statics DDL: Jan/15/2024 Length: 24 Months Supervisors: Required (But Not necessarily required prior to the application) Thesis TOEFL 90 (writing 25, speaking 25), IELTS 7.0 (writing 6.5, speaking 6.5) Western UniversityRankings #3 (Provincial) #114 (QS) #300 (US) Location London, Ontari Programs MSc - CS Length: 4 Terms Course-based, project-based or thesis-based TOEFL: 92/20, IELTS: 6.5/6 DDL: Feb/15/2024 (Mid-April Shall receive the Acceptance Notification) MESc - ECE Length: 6 Terms Thesis-based TOEFL: 86/20, IELTS: 6.5/6 DDL: Jul/31/2024 MSc - Statistics **Length: ** 3 Terms (project-based) 6 Terms (Thesis-based) TOEFL: 86/20; IELTS: 6.5/6 DDL: Feb/15/2024 MDA - Data Science Length: 3 Terms IELTS: 7.0/6.5 Course-based Université de MontréalRankings #2 (Provincial) #141 (QS) #156 (US) Location Montreal, Quebec Programs Most Programs are French Only University of CalgaryRankings #2 (Provincial) #182 (QS) #175 (US) Location Calgary, Alberta Programs Supervisors: For Thesis-based only. A supervisor is required, but is not required prior to the start of the program MEng - ECE Length: 2Y The program can often be completed in one to two years of full-time study course-based TOEFL: 86/20; IELTS: 6.5/6.0 DDL: Mar/1/2024 We encourage you to apply early as this program receives a high volume of applications and reaches capacity quickly. We send offers to qualified applicants on a rolling basis. MEng - ECE - Thesis Length: 2Y Thesis-based TOEFL: 86/20; IELTS: 6.5/6.0 DDL: 2023-09-25: NOT Accepting Applications MSc - ECE Length: 20Months Thesis-based TOEFL: 86/20; IELTS: 6.5/6 DDL: Jan/31/2024 MSc - CS Length: 2Y Thesis-based GRE: Expected Special consideration will be given to those with GRE scores of at least 600 verbal, 750 quantitative, and 720 analytical (5.5 in the new format). Applicants from outside Canada are expected to apply with GRE scores. TOEFL: 97; IELTS: 7.0/6.5 DDL: Jan/15/2024 (Estimated) MDSA - DS + Analystics course-based Length: 1Y IELTS: 6.5/6.0 DDL: For admission September 1: Canadian and Permanent Residents: July 3 For admission January 1: Canadian and Permanent Residents: October 3 International: September 1 MSc - Statistics Thesis-based Length: 2Year IELTS: 7.0/6.5 DDL: Jan/15/2024 3 References MSc - Statistics course-based Length: 1~2 Year IELTS: 7.0/6.5 DDL: Jan/15/2024 3 References McMaster UniversityRankings #4 (Provincial) #189(QS) #138 (US) Location Hamilton, Ontari Programs… University of OttawaRankings #5 (Provincial) #203 (QS) #215 (US) Location Ottawa, Ontari Programs… Queen’s University at KingstonRankings #6 (Provincial) #209 (QS) #429 (US) Location Kingston, Ontari Programs Dalhousie UniversityRankings #1 (Provincial) #298 (QS) #314 (US) Location Halifax, Nova Scotia Programs Simon Fraser UniversityRankings #2 (Provincial) #318 (QS) #317 (US) Location Burnaby, British Columbia Programs University of VictoriaRankings #3 (Provincial) #322 (QS) #324 (US) Location Victoria, British Columbia Programs National University of SingaporeNanyang Technological University, Singapore ?The University of Hong Kong?The Chinese University of Hong Kong?The Hong Kong University of Science and Technology Immigration PoliciesCanada Federal Government - EE Provincial Nomination British Columbia https://www.welcomebc.ca/Study-in-B-C/Stay-in-B-C-After-Studying Ontari https://www.ontario.ca/page/ontario-immigrant-nominee-program-oinp Quebec https://www.quebec.ca/en/education/study-quebec/staying-after-studies Nova Scotia https://novascotiaimmigration.com/study-here/after-you-graduate/ Alberta https://study.alberta.ca/after-graduation/immigrate-to-canada/ Singapore …","link":"/2023/09/25/2023-09-25-School-List/"}],"tags":[{"name":"Hadoop","slug":"Hadoop","link":"/tags/Hadoop/"},{"name":"Big Data","slug":"Big-Data","link":"/tags/Big-Data/"},{"name":"課程作業","slug":"課程作業","link":"/tags/%E8%AA%B2%E7%A8%8B%E4%BD%9C%E6%A5%AD/"},{"name":"Hardware","slug":"Hardware","link":"/tags/Hardware/"},{"name":"Performance Improve","slug":"Performance-Improve","link":"/tags/Performance-Improve/"},{"name":"DIY","slug":"DIY","link":"/tags/DIY/"},{"name":"VPN","slug":"VPN","link":"/tags/VPN/"},{"name":"Clash","slug":"Clash","link":"/tags/Clash/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"Systemd","slug":"Systemd","link":"/tags/Systemd/"},{"name":"ssh","slug":"ssh","link":"/tags/ssh/"},{"name":"learn","slug":"learn","link":"/tags/learn/"},{"name":"记录","slug":"记录","link":"/tags/%E8%AE%B0%E5%BD%95/"},{"name":"KinectV2","slug":"KinectV2","link":"/tags/KinectV2/"},{"name":"Opencv","slug":"Opencv","link":"/tags/Opencv/"},{"name":"Tranformer","slug":"Tranformer","link":"/tags/Tranformer/"},{"name":"AI","slug":"AI","link":"/tags/AI/"},{"name":"ViT","slug":"ViT","link":"/tags/ViT/"},{"name":"PaperReview","slug":"PaperReview","link":"/tags/PaperReview/"},{"name":"OpenPose","slug":"OpenPose","link":"/tags/OpenPose/"},{"name":"Pose Estimation","slug":"Pose-Estimation","link":"/tags/Pose-Estimation/"},{"name":"PAF","slug":"PAF","link":"/tags/PAF/"},{"name":"ML","slug":"ML","link":"/tags/ML/"},{"name":"TJU","slug":"TJU","link":"/tags/TJU/"},{"name":"评教","slug":"评教","link":"/tags/%E8%AF%84%E6%95%99/"},{"name":"playwright","slug":"playwright","link":"/tags/playwright/"},{"name":"Git","slug":"Git","link":"/tags/Git/"},{"name":"学习","slug":"学习","link":"/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"数据结构","slug":"数据结构","link":"/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"期末复习","slug":"期末复习","link":"/tags/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/"},{"name":"笔记","slug":"笔记","link":"/tags/%E7%AC%94%E8%AE%B0/"}],"categories":[{"name":"Diary","slug":"Diary","link":"/categories/Diary/"},{"name":"Post","slug":"Post","link":"/categories/Post/"},{"name":"PaperReview","slug":"PaperReview","link":"/categories/PaperReview/"},{"name":"Note","slug":"Note","link":"/categories/Note/"}],"pages":[{"title":"Categories","text":"","link":"/categories/index.html"},{"title":"gallery","text":"","link":"/gallery/index.html"},{"title":"movie","text":"恩智浦公司实训成果展示 2023-06-13 (function(){var player = new DPlayer({\"container\":document.getElementById(\"dplayer0\"),\"autoplay\":true,\"preload\":\"auto\",\"video\":{\"url\":\"/movie/nxp_result.mp4\"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()","link":"/movie/index.html"},{"title":"Link","text":"","link":"/link/index.html"},{"title":"Tags","text":"","link":"/tags/index.html"},{"title":"music","text":"","link":"/music/index.html"},{"title":"","text":"","link":"/pdf/index.html"},{"title":"数据结构期末复习-图","text":"图图的定义、存储结构定义 $G=(V, E)$, $V={v|v\\in Some\\ Entity}$, $E={(v, u)|v, u \\in V}$ 带权图 = 网络 子图：有$G=(V, E)$ 和 $G’=(V’, E’)$ 且 $V’\\in V, E’\\in E$ 则认为 $G’$ 是 G 的子图 邻接顶点为一条边的两个顶点 邻接矩阵 本质上就是一个 $n\\times n$ 的二维数组 G.edge[i][j] = 1 (存在边) or 0 -&gt; 有/无向图 G.edge[i][j] = Weight, INF (不存在边), 0 (i==j) -&gt; 网络（带权图） 邻接表 常见的实现是 vector&lt;vector&lt;int&gt; &gt; graph graph[i].size() 为结点 i 连接的边数 C 方面还是建议使用 &lt;dest, cost, link&gt; 的结构保存边 图的遍历（广搜，深搜） n 为顶点个数，e 为边数 Prim 构建最小生成树 手写一下1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768type Node struct{ data int}type Edge struct{ v *Node w int}type Graph struct{ nodes []*Node edges map[Node] []*Edge}// Prim // 0 -&gt; 1(28) 5(10) // 1 -&gt; 0(28) 6(14) 2(16) // 2 -&gt; 1(16) 3(12) // 3 -&gt; 4(22) 6(18) 2(12) // 4 -&gt; 5(25) 6(24) 3(22) // 5 -&gt; 0(10) 4(25) // 6 -&gt; 1(14) 4(24) 3(18) // Add 0 -10-&gt; 5// Add 5 -25-&gt; 4// Add 4 -22-&gt; 3// Add 3 -12-&gt; 2// Add 2 -16-&gt; 1// Add 1 -14-&gt; 6func (g* Graph) Prim() { lowcost := make(map[Node]int, len(g.nodes)) adjvex := make(map[Node]*Node, len(g.nodes)) u := g.nodes[0] // 初始化数据 for _, v := range g.nodes{ adjvex[*v] = u lowcost[*v] = 1000 } // 将初始点临近的点放入 for _, v := range g.edges[*u]{ lowcost[*v.v] = v.w adjvex[*v.v] = u } adjvex[*u] = nil for i:=0;i&lt;len(g.nodes);i++{ Min := 1000 var v *Node = nil // 获取最小的 lowcost 值，同时将 目标点获取出来 for _, w := range g.nodes{ if adjvex[*w] != nil &amp;&amp; lowcost[*w] &lt; Min{ v = w Min = lowcost[*w] } } if v!=nil{ // 收集该边 fmt.Printf(&quot;Add %v -%v-&gt; %v\\n&quot;, adjvex[*v], Min, v) // 对于该点的更新 adjvex[*v] = nil for _, nxt := range g.edges[*v]{ if adjvex[*nxt.v] != nil &amp;&amp; lowcost[*nxt.v] &gt; nxt.w { adjvex[*nxt.v] = v lowcost[*nxt.v] = nxt.w } } } }} 拓扑排序实现过程 !! 拓扑排序方法 关键路径实现 !! 关键路径：从源点到汇点的最长的路径长度 ve[i]：到达i结点（不是事件）最早开始时间，ve[i] = max{ve[j]+dur(&lt;i,j&gt;)}; ve[0] = 0 i 最早开始的时间为 i 的前序 j 完成且 &lt;i,j&gt; 这个步骤也完成 vl[i]：到达i结点（不是事件）最晚开始时间，vl[i] = min{vl[j]-dur(&lt;i,j&gt;)}; vl[n] = ve[n] i 最晚开始的时间为 i 的后继 j 最晚开始时间减去 &lt;i,j&gt; 步骤时间 e[k]：活动k开始的最早时间，e[k]=ve[i] 当k为&lt;i, j&gt; 时 l[k]：活动k开始的最晚时间，l[k]=vl[j]-dur(&lt;i,j&gt;)，vl[j] 是到达 j 最晚的时间，所以需要再减去一个 duration 当l[k]==e[k]我们认为k为一个关键活动 注意这里的 l[k] 和 ve[k] 的 k 不是一个 k，l, e 两个数组是对于事件，也就是边进行计算的，而 ve, vl 是对结点，即事件完成后的一个 STATE 进行的 关键路径 关键路径 最短路径实现过程 最短路思路 Dijkstra 本质上是一种贪心算法","link":"/notes/%E5%9B%BE.html"},{"title":"数据结构期末复习-排序","text":"内排序直接插入、折半插入、希尔排序 折半插入就是对插入排序的查找部分使用了二分法，但是实际上的时间复杂度还是 $O(n^2)$ 冒泡、快速排序 一趟之后 pivotkey 左边都是比他小，右边都是比他大，所以可以递归地再去排剩下的两个 快排是不稳定的 直接选择、堆排序归并排序 2023-06-16 复盘：排序的几种类型，B-树，邻接表存图","link":"/notes/%E6%8E%92%E5%BA%8F.html"},{"title":"数据结构期末复习-数组和广义表","text":"数组和广义表n 维数组$$LOC(i_1, i_2, …,i_n)= a+(i_1\\times m_2\\times m_3\\times … \\times m_n + … + i_{n-1}\\times m_n+i_n)\\times l= a + (\\sum\\limits_{j=1}^{n-1}i_j\\times\\prod\\limits_{k=j+1}^{n}m_k+i_n)\\times l\\end{align}$$ 练习1： 初始化为：A[2][3][4] $LOC(A[i][j][k]) = LOC(A[0][0][0]) + i\\times3\\times4 + j\\times 4 + k$ 练习2： 总共需要 $11\\times 11\\times 32 / 16 = 242$ 个 需要 $11\\times 32/16 = 22$ 个 $s + (8\\times 11+3)\\times 2$，这里要注意下标的起始不是 0 $s + (6\\times 11+5)\\times 2$ 上/下三角矩阵 总共元素个数：$n\\times (n+1)/2$ 个 总之画个图就会了 稀疏矩阵表示 一个三元组表示一个元素 按照行或者列排序 稀疏矩阵快速转置 矩阵转置方法 num[i] 表示 M 中第i列有num[i]个非零元素 cpot[i] 表示 M 中第i列第一个元素的在转置 T 中的位置 首先通过一次扫描所有三元组，得到num[i]的值 然后令cpot[1]=1为初始值 假设三元组从 1 开始编号，且矩阵从第 1 行还是记数 接着使用cpot[i]=cpot[i-1]+num[i-1]的递推公式开始计算cpot[i] 最后扫描一遍三元组序列，并将他们放入转置后的三元组中 由于原来的三元组本身有行优先的特性，是有序的，所以该步骤下通过cpot[i]可以得到新的位置 算法 其中 nu 为原矩阵M的列数，tu 为原矩阵非零元素个数 总时间复杂度为 $O(2\\times nu+2\\times tu)=O(nu+tu)$ 练习 特殊矩阵不会丧失随机存取，本质是一种隐射关系 稀疏矩阵压缩则已经修改为三元组的顺序表，不能进行随机存取","link":"/notes/%E6%95%B0%E7%BB%84%E5%92%8C%E5%B9%BF%E4%B9%89%E8%A1%A8.html"},{"title":"数据结构期末复习-查找","text":"查找 ASL：平均查找长度，$ASL=\\sum\\limits_{i=1}^{n}p_ic_i$ $p_i$ 为查找第 i 个元素概率，$c_i$ 为找到第 i 元素需要的比对次数 若查找失败 前半截为查找成功，等于是成功的次数减半，后半截为查找失败的次数 顺序表查找、折半查找 折半查找1234567891011121314151617181920212223/* * Find: 70 * 1 2 3 4 5 6 7 8 9 10 11 * 5 13 19 21 37 56 64 75 80 88 92 * ^ * 70 * * Find: 21 * 1 2 3 4 5 6 7 8 9 10 11 * 5 13 19 21 37 56 64 75 80 88 92 * ^ * 21 */int solve(vector&lt;int&gt; a, int x){ int l = 0, r = a.size()-1; while(l&lt;r){ int mid = (l+r+1) &gt;&gt; 1; if(a[mid]&gt;x) r = mid-1; else if(a[mid]&lt;x) l = mid+1; else return mid } return -1;} 折半查找 二叉排序树查找、插入、删除过程 $Left_{All} &lt; Current &lt; Right_{All}$，且左右子树也满足这样的特点 删除过程中： 叶子结点、只有左/右子树：很好删除 拥有左和右子树：选择左子树的最右结点，或者右子树的最左结点 构造平衡二叉树 再看看 B- 树构建、实现 !! 基于哈希函数构建哈希表（散列表） !!除留余数法解决冲突 线性深测处理 $d_i=c\\times i$ 二次深测处理 $d_i=1^2, -1^2, 2^2 ,…$","link":"/notes/%E6%9F%A5%E6%89%BE.html"},{"title":"数据结构期末复习-栈和队列","text":"栈和队列栈 栈的定义 基本操作 共享栈: 初始：top1=0, top2=MAX-1; 边界条件：top1 == top2 时还剩一个空间，top1 == top2 - 1 时满了 算法 表达式： 1234* 前缀表达式：+ x a b x - c / d e f* 中缀表达式：a x b + ( c - d / e ) x f* 后缀表达式：a b x c d e / - f x + * aka 逆波兰式 后缀形式 12* (1) A+B+C+D --&gt; AB+C+D+* (2) (A+B)*D+E/(F+A*D)+C --&gt; AB+D*EFAD*+/+C+ 中缀表达式转后缀表达式 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// Infix: a * b + ( c - d / e ) * f// Postfix a b * c d e / - f * +func Infix2postfix(str string, is_digit func(rune) bool) (ret []string, err error) { fmt.Println(&quot;Infix:\\t&quot;, str) s, err := stack.New() if err!=nil{ fmt.Println(err.Error()) return } str = str + &quot;#&quot; var buf bytes.Buffer s.Push('#') b := []rune(str) for i := 0; i &lt; len(str); i++{ c := b[i] if s.IsEmpty() &amp;&amp; c == '#'{ break } if c == ' ' { continue } if is_digit(rune(c)){ buf.WriteRune(rune(c)) }else{ if buf.String() != &quot;&quot;{ ret = append(ret, buf.String()) buf.Reset() } // 获取栈顶元素 ci, _ := s.Top() ch := ci.(rune) // 计算栈外、栈内等级，如上图所示 ous := outside(c) ins := inside(ch) if ous &gt; ins { s.Push(c) } else if ous &lt; ins { ret = append(ret, string(ch)) s.Pop() i -- } else { s.Pop() if ch != '(' { i -- } } } } fmt.Println(&quot;Infix:\\t&quot;, strings.Join(ret, &quot;&quot;)) return } 队列基本操作 循环队列的基本操作 PS: 由于 front==rear 的条件用来判断是否为空列表，所以浪费了一个空间，让 (rear+1)%MAX==front 来判断空了，上图的 MAX=8 练习 递归 1234567func convert(x, hex int){ if x == 0{ return } convert(x/hex, hex) fmt.Print(x%hex)} 12345678// Recursivefunc McCarthy91(val int) int{ if val &gt; 100 { return val - 10 }else{ return McCarthy91(McCarthy91(val+11)) }} 12345678910111213141516// Non-Recursivefunc McCarthy91(val int) int{ s, _ := stack.New() s.Push(&quot;0&quot;) for ;!s.IsEmpty();{ s.Pop() if val &gt; 100{ val -= 10 }else{ s.Push(&quot;0&quot;) s.Push(&quot;0&quot;) val += 11 } } return val}","link":"/notes/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97.html"},{"title":"数据结构期末复习-树和二叉树","text":"树和二叉树树的定义 结点：数据元素 &amp; 指向子树 的分支 结点的度：子树个数 深度、层数：从1开始编号 森林： $m\\ (m&gt;=0)$ 棵不相交的树 二叉树定义、性质 本质上是结点的有限集合 五种形态 性质 第 i 层上之多 $2^{i-1}$ 个结点 深度为 k 的二叉树至多 $2^k-1$ 个结点，$k\\ge1$ 叶结点数量为 $n_0$，度数为 2 的结点个数为 $n_2$，则 $n_0=n_2+1$ 满二叉树 $\\ne$ 完全二叉树，完全二叉树不保证最低一层是满的。 具有 n 个结点的完全二叉树深度为 $\\lfloor log_2(n)\\rfloor+1$ 完全二叉树可以通过数组模拟，且不会浪费结点 二叉树构造 记一下链表的写法 二叉树遍历和算法（递归/非递归） 前、中、后序遍历 非递归的使用栈存储待返回的结点，然后根据遍历顺序访问结点即可 [先序|后序]+中序 可以重构 二叉树应用: 技术树/森林 和 二叉树转换 森林转二叉树 二叉树左：第一个孩子；二叉树右：兄弟 树可以唯一地转化为一棵没有右子树的二叉树（指根结点上没有右子树） 树先根遍历 = 对应二叉树的先序遍历 树后根遍历 = 对应二叉树的中序遍历 哈夫曼树的构建路径长度 树 的路径长度 ($PL$) : $PL=EPL+IPL$ 内部路径 ($IPL$) : 非叶子结点到根路径的总和 外部路径 ($EPL$) : 叶子结点到根路径的总和 带权(外部)路径长度 叶子结点本身的权重 $w_i$ 该结点路径长度乘积和:$$WPL=\\sum\\limits_{i=0}^{n-1}w_i\\times l_i$$ 带权(外部)路径长度 哈夫曼编码，求加权路径长度 求法是一个贪心，采用优先队列存储 (权值，子树) 的二元组，初始化为 n 个（权值，结点），每次选取最小的两个出队列进行合并，并重新将合并结果入队列，直到该队列中只剩一棵树。 哈夫曼树构造过程 哈夫曼树例子 优化前 优化后 哈夫曼编码 报文中出现的字符会有频次的差距，例如 CAST CAST SAT AT A TASA 中 频次为：${(C: 2), (A: 7), (S: 4), (T: 5)}$ 我们可以将每个字符看作叶子结点，其频率就是其权重。若给每个字符都赋予相同长度的编码：A:00, T:10, C:01, S:11，则编码总长度：$(2+7+4+5)\\times 2=36$ 哈夫曼编码则会将其制成哈夫曼二叉树的形式，力求得到最小的 $WPL$ (带权路径长度) 且由于该编码不会产生前缀混淆，解码时采用最长路径匹配，不会产生奇异 哈夫曼编码","link":"/notes/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91.html"},{"title":"数据结构期末复习-线性表","text":"线性表 线性表：除第一个以外都有且仅有一个前驱（同理后继） 顺序表： 是线性表的顺序存储方式，元素在连续的存储空间中，数组存储 基本操作 搜索平均比较次数：$ACN = \\frac{1}{n}\\sum\\limits_{i=0}^{n-1}(i+1) = \\frac{1+n}{2} = O(n)$ 有 $n$ 个数需要比较，第 $i$ 个正确时比较了 $i+1$ 次 这里其实有BUG，即这里的平均是：匹配成功的平均比较次数，但是显然匹配失败的比较次数大概率时 $n$ 次 插入平均数据移动次数：$AMN=\\frac{1}{n+1}\\sum\\limits_{i=0}^{n}(n-i)=\\frac{n}{2}=O(n)$ 有 $n+1$ 个位置插入，每次插入第 $i$ 个位置时会移动 $n-i$ 个 删除平均数据移动次数：$AMN=\\frac{1}{n}\\sum\\limits_{i=0}^{n-1}(n-i-1)=\\frac{n-1}{2}=O(n)$ 有 $n$ 个数可以删除，删除第 $i$ 个时需要移动 $(n-i-1)$ 个数 算法： 有序向量去重 (快慢指针) 1234567891011121314151617// uniquify // Before: [1 1 1 1 3 4 4 5 5 6]// After: [1 3 4 5 6]func uniquify(arr[] int) (length int){ fmt.Println(&quot;Before:&quot;, arr) length = len(arr) i, j := 0, 0 for ; j&lt;length;j++{ if arr[i] != arr[j] { i++ arr[i] = arr[j] } } length = i+1 fmt.Println(&quot;After: &quot;, arr[:length]) return } 有序向量查找（二分法） 12345678910111213141516171819// binary_search // Array: [1 2 4 6 7] find 7// Found: [ ^] found: idx = 4func binary_search(arr[] int, x int)(mid int){ // [l, r) l, r := 0, len(arr) for; l&lt;r;{ mid = ((l+r) &gt;&gt; 1) if arr[mid] &lt; x { l = mid+1 }else if arr[mid] &gt; x{ r = mid }else{ return } } mid = -1 return} 优缺点 优点：简单、运算方便，短小、固定长度的线性表有优越性，随机访问效率高。 缺点：顺序存储、插入删除元素需要移动，效率低。预分配空间不灵活。 链表 数据域 + 指针域 存储单元可以不连续 顺序存取 带头结点的表：即有一个没有数据域的指针作为头，可以简化链表操作的实现 基本操作 插入 首个结点之前插入（若有专门的头结点则与中间插入相同） 12newnode-&gt;link = first;first = newnode; 链表中间插入 12newnode-&gt;link = p-&gt;link;p-&gt;link = newnode; p 是被插入结点的前一个 链表末尾：单链表同中间插入（只是这个 p-&gt;link 本身就是 NULL） 删除 12q = p-&gt;link;p-&gt;link = q-&gt;link; Takeaway 算法 随堂练习 答案：(c)(f)(b)(e)(a)(d) 静态链表 使用数组模拟链表，指针域从原先的指向某个地址（虚拟地址） 变为 指向某个地址（在数组中的编号） 循环链表 最后一个结点的 link 指向 头结点 空表 双向链表 循环链表再加一个反向的指针 双向链表 顺序表 $VS$ 链表 顺序表 vs 链表","link":"/notes/%E7%BA%BF%E6%80%A7%E8%A1%A8.html"},{"title":"数据结构期末复习-绪论","text":"绪论基本概念和术语 基本概念和术语 存储结构 时间复杂度计算 时间复杂度 几个需要记住的时间复杂度表示 当$n\\ge16$时$$O(1) &lt; O(log_2N) &lt; O(N) &lt; O(Nlog_2N) &lt; O(N^2) &lt; O(N^3) &lt; O(2^N)$$ $O(Nlog_2N)$: 线性对数时间 插入排序计算时间复杂度例子 Takeaway: 计算时间复杂度时在程序边上写出赋值之类的操作，并写出完整的公式，虽然最后可以用 $O$ 符号来规约，但我猜这个完整的式子是有分的。 –","link":"/notes/%E7%BB%AA%E8%AE%BA.html"}]}